{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.997228317357663,
  "eval_steps": 500,
  "global_step": 4328,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09238942141124841,
      "grad_norm": 0.18485747277736664,
      "learning_rate": 0.00019993414517786287,
      "loss": 0.4028,
      "step": 50
    },
    {
      "epoch": 0.18477884282249682,
      "grad_norm": 0.2079707682132721,
      "learning_rate": 0.0001997366674486034,
      "loss": 0.1891,
      "step": 100
    },
    {
      "epoch": 0.27716826423374524,
      "grad_norm": 0.19829367101192474,
      "learning_rate": 0.00019940782690943637,
      "loss": 0.1727,
      "step": 150
    },
    {
      "epoch": 0.36955768564499364,
      "grad_norm": 0.18008802831172943,
      "learning_rate": 0.00019894805667506615,
      "loss": 0.1486,
      "step": 200
    },
    {
      "epoch": 0.46194710705624203,
      "grad_norm": 0.29724594950675964,
      "learning_rate": 0.00019835796230723287,
      "loss": 0.1347,
      "step": 250
    },
    {
      "epoch": 0.5543365284674905,
      "grad_norm": 0.2582339346408844,
      "learning_rate": 0.00019763832101712928,
      "loss": 0.1197,
      "step": 300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.269790381193161,
      "learning_rate": 0.00019679008064173867,
      "loss": 0.1143,
      "step": 350
    },
    {
      "epoch": 0.7391153712899873,
      "grad_norm": 0.18520645797252655,
      "learning_rate": 0.00019581435839544203,
      "loss": 0.1065,
      "step": 400
    },
    {
      "epoch": 0.8315047927012357,
      "grad_norm": 0.21565702557563782,
      "learning_rate": 0.00019471243939853908,
      "loss": 0.1016,
      "step": 450
    },
    {
      "epoch": 0.9238942141124841,
      "grad_norm": 0.21645955741405487,
      "learning_rate": 0.0001934857749846208,
      "loss": 0.1027,
      "step": 500
    },
    {
      "epoch": 1.0162836355237326,
      "grad_norm": 0.14620685577392578,
      "learning_rate": 0.0001921359807890232,
      "loss": 0.0937,
      "step": 550
    },
    {
      "epoch": 1.108673056934981,
      "grad_norm": 0.17781126499176025,
      "learning_rate": 0.0001906648346208798,
      "loss": 0.0645,
      "step": 600
    },
    {
      "epoch": 1.2010624783462294,
      "grad_norm": 0.24799656867980957,
      "learning_rate": 0.00018907427412157533,
      "loss": 0.0714,
      "step": 650
    },
    {
      "epoch": 1.2934518997574778,
      "grad_norm": 0.19111423194408417,
      "learning_rate": 0.00018736639421268545,
      "loss": 0.0668,
      "step": 700
    },
    {
      "epoch": 1.3858413211687262,
      "grad_norm": 0.16655802726745605,
      "learning_rate": 0.0001855434443367628,
      "loss": 0.0653,
      "step": 750
    },
    {
      "epoch": 1.4782307425799746,
      "grad_norm": 0.1649796962738037,
      "learning_rate": 0.0001836078254946042,
      "loss": 0.0667,
      "step": 800
    },
    {
      "epoch": 1.570620163991223,
      "grad_norm": 0.12551075220108032,
      "learning_rate": 0.00018156208708290121,
      "loss": 0.0619,
      "step": 850
    },
    {
      "epoch": 1.6630095854024716,
      "grad_norm": 0.19910883903503418,
      "learning_rate": 0.00017940892353643866,
      "loss": 0.0606,
      "step": 900
    },
    {
      "epoch": 1.75539900681372,
      "grad_norm": 0.09958337247371674,
      "learning_rate": 0.00017715117077926422,
      "loss": 0.059,
      "step": 950
    },
    {
      "epoch": 1.8477884282249684,
      "grad_norm": 0.15167254209518433,
      "learning_rate": 0.00017479180248950295,
      "loss": 0.0579,
      "step": 1000
    },
    {
      "epoch": 1.9401778496362168,
      "grad_norm": 0.23226521909236908,
      "learning_rate": 0.00017233392618273645,
      "loss": 0.0486,
      "step": 1050
    },
    {
      "epoch": 2.032567271047465,
      "grad_norm": 0.18001006543636322,
      "learning_rate": 0.00016978077911910502,
      "loss": 0.0515,
      "step": 1100
    },
    {
      "epoch": 2.1249566924587135,
      "grad_norm": 0.12915632128715515,
      "learning_rate": 0.00016713572403952403,
      "loss": 0.032,
      "step": 1150
    },
    {
      "epoch": 2.217346113869962,
      "grad_norm": 0.13517220318317413,
      "learning_rate": 0.0001644022447366296,
      "loss": 0.0317,
      "step": 1200
    },
    {
      "epoch": 2.3097355352812103,
      "grad_norm": 0.17141351103782654,
      "learning_rate": 0.0001615839414662879,
      "loss": 0.0375,
      "step": 1250
    },
    {
      "epoch": 2.4021249566924587,
      "grad_norm": 0.185337632894516,
      "learning_rate": 0.00015868452620571087,
      "loss": 0.0299,
      "step": 1300
    },
    {
      "epoch": 2.494514378103707,
      "grad_norm": 0.34526321291923523,
      "learning_rate": 0.00015570781776442426,
      "loss": 0.0332,
      "step": 1350
    },
    {
      "epoch": 2.5869037995149555,
      "grad_norm": 0.17054083943367004,
      "learning_rate": 0.00015265773675452718,
      "loss": 0.0344,
      "step": 1400
    },
    {
      "epoch": 2.679293220926204,
      "grad_norm": 0.12553559243679047,
      "learning_rate": 0.0001495383004268678,
      "loss": 0.0338,
      "step": 1450
    },
    {
      "epoch": 2.7716826423374523,
      "grad_norm": 0.1710074245929718,
      "learning_rate": 0.00014635361737993667,
      "loss": 0.0371,
      "step": 1500
    },
    {
      "epoch": 2.8640720637487007,
      "grad_norm": 0.21525605022907257,
      "learning_rate": 0.00014310788214844618,
      "loss": 0.0361,
      "step": 1550
    },
    {
      "epoch": 2.956461485159949,
      "grad_norm": 0.15991555154323578,
      "learning_rate": 0.00013980536967872378,
      "loss": 0.0337,
      "step": 1600
    },
    {
      "epoch": 3.0488509065711975,
      "grad_norm": 0.13615749776363373,
      "learning_rate": 0.00013645042969819544,
      "loss": 0.0255,
      "step": 1650
    },
    {
      "epoch": 3.141240327982446,
      "grad_norm": 0.12402395904064178,
      "learning_rate": 0.0001330474809863752,
      "loss": 0.0185,
      "step": 1700
    },
    {
      "epoch": 3.2336297493936943,
      "grad_norm": 0.1206909790635109,
      "learning_rate": 0.00012960100555490617,
      "loss": 0.018,
      "step": 1750
    },
    {
      "epoch": 3.3260191708049427,
      "grad_norm": 0.09619126468896866,
      "learning_rate": 0.0001261155427443192,
      "loss": 0.0166,
      "step": 1800
    },
    {
      "epoch": 3.418408592216191,
      "grad_norm": 0.2174682468175888,
      "learning_rate": 0.00012259568324528335,
      "loss": 0.0179,
      "step": 1850
    },
    {
      "epoch": 3.51079801362744,
      "grad_norm": 0.09133201837539673,
      "learning_rate": 0.00011904606305222381,
      "loss": 0.0201,
      "step": 1900
    },
    {
      "epoch": 3.603187435038688,
      "grad_norm": 0.18268020451068878,
      "learning_rate": 0.00011547135735726992,
      "loss": 0.0169,
      "step": 1950
    },
    {
      "epoch": 3.6955768564499367,
      "grad_norm": 0.13104121387004852,
      "learning_rate": 0.00011187627439257638,
      "loss": 0.0163,
      "step": 2000
    },
    {
      "epoch": 3.7879662778611847,
      "grad_norm": 0.11355523020029068,
      "learning_rate": 0.00010826554922912733,
      "loss": 0.0193,
      "step": 2050
    },
    {
      "epoch": 3.8803556992724335,
      "grad_norm": 0.09651805460453033,
      "learning_rate": 0.00010464393754019131,
      "loss": 0.018,
      "step": 2100
    },
    {
      "epoch": 3.9727451206836815,
      "grad_norm": 0.09524080157279968,
      "learning_rate": 0.00010101620933764071,
      "loss": 0.0172,
      "step": 2150
    },
    {
      "epoch": 4.06513454209493,
      "grad_norm": 0.07456375658512115,
      "learning_rate": 9.73871426893865e-05,
      "loss": 0.0095,
      "step": 2200
    },
    {
      "epoch": 4.157523963506178,
      "grad_norm": 0.05814855173230171,
      "learning_rate": 9.376151742620147e-05,
      "loss": 0.0098,
      "step": 2250
    },
    {
      "epoch": 4.249913384917427,
      "grad_norm": 0.025658678263425827,
      "learning_rate": 9.01441088462225e-05,
      "loss": 0.0104,
      "step": 2300
    },
    {
      "epoch": 4.342302806328675,
      "grad_norm": 0.07024179399013519,
      "learning_rate": 8.65396814254222e-05,
      "loss": 0.0108,
      "step": 2350
    },
    {
      "epoch": 4.434692227739924,
      "grad_norm": 0.23024001717567444,
      "learning_rate": 8.29529825423347e-05,
      "loss": 0.0081,
      "step": 2400
    },
    {
      "epoch": 4.527081649151172,
      "grad_norm": 0.05647628381848335,
      "learning_rate": 7.938873622530005e-05,
      "loss": 0.0079,
      "step": 2450
    },
    {
      "epoch": 4.619471070562421,
      "grad_norm": 0.06198539957404137,
      "learning_rate": 7.58516369304635e-05,
      "loss": 0.0078,
      "step": 2500
    },
    {
      "epoch": 4.711860491973669,
      "grad_norm": 0.03135460615158081,
      "learning_rate": 7.23463433587239e-05,
      "loss": 0.0092,
      "step": 2550
    },
    {
      "epoch": 4.8042499133849175,
      "grad_norm": 0.08753654360771179,
      "learning_rate": 6.887747231977533e-05,
      "loss": 0.0058,
      "step": 2600
    },
    {
      "epoch": 4.896639334796166,
      "grad_norm": 0.06828644871711731,
      "learning_rate": 6.544959265132358e-05,
      "loss": 0.0076,
      "step": 2650
    },
    {
      "epoch": 4.989028756207414,
      "grad_norm": 0.10161576420068741,
      "learning_rate": 6.206721920148608e-05,
      "loss": 0.0077,
      "step": 2700
    },
    {
      "epoch": 5.081418177618662,
      "grad_norm": 0.018465016037225723,
      "learning_rate": 5.873480688230164e-05,
      "loss": 0.0042,
      "step": 2750
    },
    {
      "epoch": 5.173807599029911,
      "grad_norm": 0.31168586015701294,
      "learning_rate": 5.545674480218161e-05,
      "loss": 0.0042,
      "step": 2800
    },
    {
      "epoch": 5.26619702044116,
      "grad_norm": 0.03732452541589737,
      "learning_rate": 5.2237350485030865e-05,
      "loss": 0.0041,
      "step": 2850
    },
    {
      "epoch": 5.358586441852408,
      "grad_norm": 0.14519253373146057,
      "learning_rate": 4.9080864183652174e-05,
      "loss": 0.0045,
      "step": 2900
    },
    {
      "epoch": 5.450975863263657,
      "grad_norm": 0.041573666036129,
      "learning_rate": 4.5991443294924776e-05,
      "loss": 0.0034,
      "step": 2950
    },
    {
      "epoch": 5.543365284674905,
      "grad_norm": 0.10270236432552338,
      "learning_rate": 4.2973156884111344e-05,
      "loss": 0.0034,
      "step": 3000
    },
    {
      "epoch": 5.6357547060861535,
      "grad_norm": 0.0626637190580368,
      "learning_rate": 4.002998032550666e-05,
      "loss": 0.0056,
      "step": 3050
    },
    {
      "epoch": 5.728144127497401,
      "grad_norm": 0.04340772330760956,
      "learning_rate": 3.7165790066486464e-05,
      "loss": 0.0035,
      "step": 3100
    },
    {
      "epoch": 5.82053354890865,
      "grad_norm": 0.043874360620975494,
      "learning_rate": 3.4384358521852236e-05,
      "loss": 0.0042,
      "step": 3150
    },
    {
      "epoch": 5.912922970319898,
      "grad_norm": 0.058316294103860855,
      "learning_rate": 3.168934910519722e-05,
      "loss": 0.0034,
      "step": 3200
    },
    {
      "epoch": 6.005312391731147,
      "grad_norm": 0.012635412625968456,
      "learning_rate": 2.9084311403837163e-05,
      "loss": 0.0036,
      "step": 3250
    },
    {
      "epoch": 6.097701813142395,
      "grad_norm": 0.03468484804034233,
      "learning_rate": 2.6572676503661764e-05,
      "loss": 0.0018,
      "step": 3300
    },
    {
      "epoch": 6.190091234553644,
      "grad_norm": 0.024235278367996216,
      "learning_rate": 2.4157752470063532e-05,
      "loss": 0.0021,
      "step": 3350
    },
    {
      "epoch": 6.282480655964892,
      "grad_norm": 0.07036817073822021,
      "learning_rate": 2.184271999089662e-05,
      "loss": 0.0019,
      "step": 3400
    },
    {
      "epoch": 6.374870077376141,
      "grad_norm": 0.053666602820158005,
      "learning_rate": 1.963062818720409e-05,
      "loss": 0.0017,
      "step": 3450
    },
    {
      "epoch": 6.467259498787389,
      "grad_norm": 0.022308461368083954,
      "learning_rate": 1.752439059723171e-05,
      "loss": 0.0018,
      "step": 3500
    },
    {
      "epoch": 6.559648920198637,
      "grad_norm": 0.02675762213766575,
      "learning_rate": 1.552678133901676e-05,
      "loss": 0.0023,
      "step": 3550
    },
    {
      "epoch": 6.652038341609885,
      "grad_norm": 0.0954938679933548,
      "learning_rate": 1.364043145660725e-05,
      "loss": 0.0016,
      "step": 3600
    },
    {
      "epoch": 6.744427763021134,
      "grad_norm": 0.008655267767608166,
      "learning_rate": 1.1867825454723024e-05,
      "loss": 0.0015,
      "step": 3650
    },
    {
      "epoch": 6.836817184432382,
      "grad_norm": 0.008289945311844349,
      "learning_rate": 1.0211298026423555e-05,
      "loss": 0.0024,
      "step": 3700
    },
    {
      "epoch": 6.929206605843631,
      "grad_norm": 0.03689711168408394,
      "learning_rate": 8.673030978091989e-06,
      "loss": 0.0015,
      "step": 3750
    },
    {
      "epoch": 7.021596027254879,
      "grad_norm": 0.004462845623493195,
      "learning_rate": 7.255050355785697e-06,
      "loss": 0.0012,
      "step": 3800
    },
    {
      "epoch": 7.113985448666128,
      "grad_norm": 0.024662142619490623,
      "learning_rate": 5.959223776738132e-06,
      "loss": 0.0008,
      "step": 3850
    },
    {
      "epoch": 7.206374870077376,
      "grad_norm": 0.007790735457092524,
      "learning_rate": 4.787257969527004e-06,
      "loss": 0.0014,
      "step": 3900
    },
    {
      "epoch": 7.298764291488625,
      "grad_norm": 0.010176335461437702,
      "learning_rate": 3.740696526147991e-06,
      "loss": 0.0015,
      "step": 3950
    },
    {
      "epoch": 7.3911537128998726,
      "grad_norm": 0.010269149206578732,
      "learning_rate": 2.8209178689553083e-06,
      "loss": 0.0016,
      "step": 4000
    },
    {
      "epoch": 7.483543134311121,
      "grad_norm": 0.03538968041539192,
      "learning_rate": 2.029133435146424e-06,
      "loss": 0.0012,
      "step": 4050
    },
    {
      "epoch": 7.575932555722369,
      "grad_norm": 0.038961634039878845,
      "learning_rate": 1.3663860811825468e-06,
      "loss": 0.0012,
      "step": 4100
    },
    {
      "epoch": 7.668321977133618,
      "grad_norm": 0.007986770011484623,
      "learning_rate": 8.335487092460126e-07,
      "loss": 0.0012,
      "step": 4150
    },
    {
      "epoch": 7.760711398544867,
      "grad_norm": 0.018529433757066727,
      "learning_rate": 4.3132311754395805e-07,
      "loss": 0.0012,
      "step": 4200
    },
    {
      "epoch": 7.853100819956115,
      "grad_norm": 0.008641758002340794,
      "learning_rate": 1.602390759723904e-07,
      "loss": 0.0009,
      "step": 4250
    },
    {
      "epoch": 7.945490241367364,
      "grad_norm": 0.021798808127641678,
      "learning_rate": 2.0653628358158205e-08,
      "loss": 0.0012,
      "step": 4300
    },
    {
      "epoch": 7.997228317357663,
      "step": 4328,
      "total_flos": 3.525645772889303e+18,
      "train_loss": 0.0355306716873388,
      "train_runtime": 63442.1885,
      "train_samples_per_second": 1.092,
      "train_steps_per_second": 0.068
    }
  ],
  "logging_steps": 50,
  "max_steps": 4328,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.525645772889303e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
