{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.989173583543847,
  "eval_steps": 500,
  "global_step": 5190,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09623481294358234,
      "grad_norm": 0.3276306390762329,
      "learning_rate": 0.00019995420248742534,
      "loss": 0.4258,
      "step": 50
    },
    {
      "epoch": 0.19246962588716468,
      "grad_norm": 0.2136574536561966,
      "learning_rate": 0.00019981685189794453,
      "loss": 0.2189,
      "step": 100
    },
    {
      "epoch": 0.28870443883074703,
      "grad_norm": 0.25235700607299805,
      "learning_rate": 0.00019958807403786452,
      "loss": 0.1819,
      "step": 150
    },
    {
      "epoch": 0.38493925177432936,
      "grad_norm": 0.22011816501617432,
      "learning_rate": 0.00019926807845632383,
      "loss": 0.1703,
      "step": 200
    },
    {
      "epoch": 0.4811740647179117,
      "grad_norm": 0.24168761074543,
      "learning_rate": 0.00019885715825335582,
      "loss": 0.1584,
      "step": 250
    },
    {
      "epoch": 0.5774088776614941,
      "grad_norm": 0.24341462552547455,
      "learning_rate": 0.00019835568981142374,
      "loss": 0.1473,
      "step": 300
    },
    {
      "epoch": 0.6736436906050763,
      "grad_norm": 0.1406531035900116,
      "learning_rate": 0.00019776413245067305,
      "loss": 0.1226,
      "step": 350
    },
    {
      "epoch": 0.7698785035486587,
      "grad_norm": 0.24387897551059723,
      "learning_rate": 0.00019708302800821724,
      "loss": 0.1245,
      "step": 400
    },
    {
      "epoch": 0.8661133164922411,
      "grad_norm": 0.28864479064941406,
      "learning_rate": 0.00019631300034184153,
      "loss": 0.1285,
      "step": 450
    },
    {
      "epoch": 0.9623481294358234,
      "grad_norm": 0.18376164138317108,
      "learning_rate": 0.00019545475475858066,
      "loss": 0.1062,
      "step": 500
    },
    {
      "epoch": 1.0585829423794058,
      "grad_norm": 0.1902438998222351,
      "learning_rate": 0.00019450907736869244,
      "loss": 0.1012,
      "step": 550
    },
    {
      "epoch": 1.1548177553229881,
      "grad_norm": 0.16907672584056854,
      "learning_rate": 0.00019347683436561999,
      "loss": 0.0822,
      "step": 600
    },
    {
      "epoch": 1.2510525682665703,
      "grad_norm": 0.12050021439790726,
      "learning_rate": 0.00019235897123260154,
      "loss": 0.0839,
      "step": 650
    },
    {
      "epoch": 1.347287381210153,
      "grad_norm": 0.23135966062545776,
      "learning_rate": 0.00019115651187665497,
      "loss": 0.0864,
      "step": 700
    },
    {
      "epoch": 1.443522194153735,
      "grad_norm": 0.12071835249662399,
      "learning_rate": 0.00018987055769072972,
      "loss": 0.0828,
      "step": 750
    },
    {
      "epoch": 1.5397570070973174,
      "grad_norm": 0.2131635546684265,
      "learning_rate": 0.0001885022865448858,
      "loss": 0.0767,
      "step": 800
    },
    {
      "epoch": 1.6359918200408998,
      "grad_norm": 0.13746264576911926,
      "learning_rate": 0.00018705295170742337,
      "loss": 0.0727,
      "step": 850
    },
    {
      "epoch": 1.732226632984482,
      "grad_norm": 0.148682102560997,
      "learning_rate": 0.0001855238806969513,
      "loss": 0.0692,
      "step": 900
    },
    {
      "epoch": 1.8284614459280646,
      "grad_norm": 0.21137996017932892,
      "learning_rate": 0.0001839164740664462,
      "loss": 0.069,
      "step": 950
    },
    {
      "epoch": 1.9246962588716467,
      "grad_norm": 0.18930914998054504,
      "learning_rate": 0.0001822322041204155,
      "loss": 0.075,
      "step": 1000
    },
    {
      "epoch": 2.0209310718152294,
      "grad_norm": 0.12023274600505829,
      "learning_rate": 0.0001804726135663399,
      "loss": 0.0634,
      "step": 1050
    },
    {
      "epoch": 2.1171658847588115,
      "grad_norm": 0.16421562433242798,
      "learning_rate": 0.00017863931410162987,
      "loss": 0.0469,
      "step": 1100
    },
    {
      "epoch": 2.2134006977023937,
      "grad_norm": 0.15106864273548126,
      "learning_rate": 0.00017673398493739118,
      "loss": 0.0522,
      "step": 1150
    },
    {
      "epoch": 2.3096355106459763,
      "grad_norm": 0.1259806901216507,
      "learning_rate": 0.00017475837126035106,
      "loss": 0.0532,
      "step": 1200
    },
    {
      "epoch": 2.4058703235895584,
      "grad_norm": 0.10228735953569412,
      "learning_rate": 0.00017271428263435375,
      "loss": 0.0513,
      "step": 1250
    },
    {
      "epoch": 2.5021051365331406,
      "grad_norm": 0.11809967458248138,
      "learning_rate": 0.0001706035913428904,
      "loss": 0.0446,
      "step": 1300
    },
    {
      "epoch": 2.598339949476723,
      "grad_norm": 0.2046433985233307,
      "learning_rate": 0.00016842823067418018,
      "loss": 0.0519,
      "step": 1350
    },
    {
      "epoch": 2.694574762420306,
      "grad_norm": 0.17867712676525116,
      "learning_rate": 0.00016619019315037472,
      "loss": 0.0485,
      "step": 1400
    },
    {
      "epoch": 2.790809575363888,
      "grad_norm": 0.1385481357574463,
      "learning_rate": 0.00016389152870250676,
      "loss": 0.0477,
      "step": 1450
    },
    {
      "epoch": 2.88704438830747,
      "grad_norm": 0.2280569225549698,
      "learning_rate": 0.0001615343427928555,
      "loss": 0.0408,
      "step": 1500
    },
    {
      "epoch": 2.9832792012510527,
      "grad_norm": 0.12736748158931732,
      "learning_rate": 0.00015912079448644764,
      "loss": 0.0437,
      "step": 1550
    },
    {
      "epoch": 3.079514014194635,
      "grad_norm": 0.10996425151824951,
      "learning_rate": 0.00015665309447346145,
      "loss": 0.0338,
      "step": 1600
    },
    {
      "epoch": 3.175748827138217,
      "grad_norm": 0.08187516778707504,
      "learning_rate": 0.0001541335030443444,
      "loss": 0.0328,
      "step": 1650
    },
    {
      "epoch": 3.2719836400817996,
      "grad_norm": 0.09358459711074829,
      "learning_rate": 0.00015156432801949972,
      "loss": 0.0348,
      "step": 1700
    },
    {
      "epoch": 3.368218453025382,
      "grad_norm": 0.1263999491930008,
      "learning_rate": 0.00014894792263543745,
      "loss": 0.032,
      "step": 1750
    },
    {
      "epoch": 3.4644532659689644,
      "grad_norm": 0.19505321979522705,
      "learning_rate": 0.0001462866833893272,
      "loss": 0.037,
      "step": 1800
    },
    {
      "epoch": 3.5606880789125466,
      "grad_norm": 0.15178801119327545,
      "learning_rate": 0.00014358304784392568,
      "loss": 0.0334,
      "step": 1850
    },
    {
      "epoch": 3.656922891856129,
      "grad_norm": 0.1874648928642273,
      "learning_rate": 0.00014083949239489076,
      "loss": 0.0293,
      "step": 1900
    },
    {
      "epoch": 3.7531577047997113,
      "grad_norm": 0.12365878373384476,
      "learning_rate": 0.00013805853000252585,
      "loss": 0.0306,
      "step": 1950
    },
    {
      "epoch": 3.8493925177432935,
      "grad_norm": 0.10225189477205276,
      "learning_rate": 0.0001352427078900336,
      "loss": 0.0309,
      "step": 2000
    },
    {
      "epoch": 3.945627330686876,
      "grad_norm": 0.1244543269276619,
      "learning_rate": 0.00013239460521038623,
      "loss": 0.031,
      "step": 2050
    },
    {
      "epoch": 4.041862143630459,
      "grad_norm": 0.0932266116142273,
      "learning_rate": 0.0001295168306839494,
      "loss": 0.0235,
      "step": 2100
    },
    {
      "epoch": 4.13809695657404,
      "grad_norm": 0.05513036996126175,
      "learning_rate": 0.00012661202020902433,
      "loss": 0.0211,
      "step": 2150
    },
    {
      "epoch": 4.234331769517623,
      "grad_norm": 0.15260453522205353,
      "learning_rate": 0.00012368283444749603,
      "loss": 0.0245,
      "step": 2200
    },
    {
      "epoch": 4.330566582461206,
      "grad_norm": 0.09098511934280396,
      "learning_rate": 0.00012073195638779943,
      "loss": 0.0201,
      "step": 2250
    },
    {
      "epoch": 4.426801395404787,
      "grad_norm": 0.12815020978450775,
      "learning_rate": 0.00011776208888743554,
      "loss": 0.0192,
      "step": 2300
    },
    {
      "epoch": 4.52303620834837,
      "grad_norm": 0.0827954038977623,
      "learning_rate": 0.00011477595219728817,
      "loss": 0.0184,
      "step": 2350
    },
    {
      "epoch": 4.6192710212919526,
      "grad_norm": 0.14232149720191956,
      "learning_rate": 0.00011177628147000961,
      "loss": 0.0185,
      "step": 2400
    },
    {
      "epoch": 4.715505834235534,
      "grad_norm": 0.0787048265337944,
      "learning_rate": 0.00010876582425475694,
      "loss": 0.0202,
      "step": 2450
    },
    {
      "epoch": 4.811740647179117,
      "grad_norm": 0.0420273095369339,
      "learning_rate": 0.00010574733798057358,
      "loss": 0.0212,
      "step": 2500
    },
    {
      "epoch": 4.9079754601226995,
      "grad_norm": 0.13279025256633759,
      "learning_rate": 0.00010272358743072152,
      "loss": 0.0181,
      "step": 2550
    },
    {
      "epoch": 5.004210273066282,
      "grad_norm": 0.08144194632768631,
      "learning_rate": 9.969734221027732e-05,
      "loss": 0.0201,
      "step": 2600
    },
    {
      "epoch": 5.100445086009864,
      "grad_norm": 0.05842671915888786,
      "learning_rate": 9.667137420931173e-05,
      "loss": 0.0139,
      "step": 2650
    },
    {
      "epoch": 5.196679898953446,
      "grad_norm": 0.12436310201883316,
      "learning_rate": 9.364845506397624e-05,
      "loss": 0.0114,
      "step": 2700
    },
    {
      "epoch": 5.292914711897029,
      "grad_norm": 0.036954864859580994,
      "learning_rate": 9.063135361782227e-05,
      "loss": 0.0153,
      "step": 2750
    },
    {
      "epoch": 5.389149524840611,
      "grad_norm": 0.054299451410770416,
      "learning_rate": 8.762283338567821e-05,
      "loss": 0.0138,
      "step": 2800
    },
    {
      "epoch": 5.485384337784193,
      "grad_norm": 0.08867271989583969,
      "learning_rate": 8.462565002240732e-05,
      "loss": 0.0132,
      "step": 2850
    },
    {
      "epoch": 5.581619150727776,
      "grad_norm": 0.10818754881620407,
      "learning_rate": 8.164254879886494e-05,
      "loss": 0.0129,
      "step": 2900
    },
    {
      "epoch": 5.6778539636713585,
      "grad_norm": 0.07036066055297852,
      "learning_rate": 7.867626208736703e-05,
      "loss": 0.0094,
      "step": 2950
    },
    {
      "epoch": 5.77408877661494,
      "grad_norm": 0.10789891332387924,
      "learning_rate": 7.572950685897294e-05,
      "loss": 0.0139,
      "step": 3000
    },
    {
      "epoch": 5.870323589558523,
      "grad_norm": 0.04661475494503975,
      "learning_rate": 7.280498219487525e-05,
      "loss": 0.014,
      "step": 3050
    },
    {
      "epoch": 5.9665584025021055,
      "grad_norm": 0.08471829444169998,
      "learning_rate": 6.990536681417554e-05,
      "loss": 0.0133,
      "step": 3100
    },
    {
      "epoch": 6.062793215445687,
      "grad_norm": 0.06975574046373367,
      "learning_rate": 6.703331662031098e-05,
      "loss": 0.0122,
      "step": 3150
    },
    {
      "epoch": 6.15902802838927,
      "grad_norm": 0.037387534976005554,
      "learning_rate": 6.419146226837894e-05,
      "loss": 0.0087,
      "step": 3200
    },
    {
      "epoch": 6.255262841332852,
      "grad_norm": 0.04963676258921623,
      "learning_rate": 6.138240675558778e-05,
      "loss": 0.0104,
      "step": 3250
    },
    {
      "epoch": 6.351497654276434,
      "grad_norm": 0.06839150935411453,
      "learning_rate": 5.860872303704089e-05,
      "loss": 0.0101,
      "step": 3300
    },
    {
      "epoch": 6.447732467220017,
      "grad_norm": 0.055774424225091934,
      "learning_rate": 5.5872951669037855e-05,
      "loss": 0.0087,
      "step": 3350
    },
    {
      "epoch": 6.543967280163599,
      "grad_norm": 0.05537399649620056,
      "learning_rate": 5.317759848205124e-05,
      "loss": 0.0076,
      "step": 3400
    },
    {
      "epoch": 6.640202093107182,
      "grad_norm": 0.2047627568244934,
      "learning_rate": 5.052513228551048e-05,
      "loss": 0.014,
      "step": 3450
    },
    {
      "epoch": 6.736436906050764,
      "grad_norm": 0.03535187616944313,
      "learning_rate": 4.791798260649538e-05,
      "loss": 0.011,
      "step": 3500
    },
    {
      "epoch": 6.832671718994346,
      "grad_norm": 0.0798368752002716,
      "learning_rate": 4.535853746441018e-05,
      "loss": 0.0088,
      "step": 3550
    },
    {
      "epoch": 6.928906531937929,
      "grad_norm": 0.06662507355213165,
      "learning_rate": 4.2849141183676365e-05,
      "loss": 0.0091,
      "step": 3600
    },
    {
      "epoch": 7.0251413448815105,
      "grad_norm": 0.006249661091715097,
      "learning_rate": 4.039209224644845e-05,
      "loss": 0.0121,
      "step": 3650
    },
    {
      "epoch": 7.121376157825093,
      "grad_norm": 0.041180044412612915,
      "learning_rate": 3.7989641187318326e-05,
      "loss": 0.0077,
      "step": 3700
    },
    {
      "epoch": 7.217610970768676,
      "grad_norm": 0.05255213379859924,
      "learning_rate": 3.5643988531937924e-05,
      "loss": 0.0081,
      "step": 3750
    },
    {
      "epoch": 7.313845783712258,
      "grad_norm": 0.05082828179001808,
      "learning_rate": 3.3357282781446784e-05,
      "loss": 0.0058,
      "step": 3800
    },
    {
      "epoch": 7.41008059665584,
      "grad_norm": 0.07735415548086166,
      "learning_rate": 3.1131618444552145e-05,
      "loss": 0.0083,
      "step": 3850
    },
    {
      "epoch": 7.506315409599423,
      "grad_norm": 0.036275796592235565,
      "learning_rate": 2.8969034119063176e-05,
      "loss": 0.0066,
      "step": 3900
    },
    {
      "epoch": 7.602550222543005,
      "grad_norm": 0.04097558930516243,
      "learning_rate": 2.6871510624636586e-05,
      "loss": 0.0068,
      "step": 3950
    },
    {
      "epoch": 7.698785035486587,
      "grad_norm": 0.029570871964097023,
      "learning_rate": 2.4840969188444753e-05,
      "loss": 0.0086,
      "step": 4000
    },
    {
      "epoch": 7.79501984843017,
      "grad_norm": 0.10542034357786179,
      "learning_rate": 2.287926968542674e-05,
      "loss": 0.0075,
      "step": 4050
    },
    {
      "epoch": 7.891254661373752,
      "grad_norm": 0.06268776208162308,
      "learning_rate": 2.0988208934735666e-05,
      "loss": 0.0081,
      "step": 4100
    },
    {
      "epoch": 7.987489474317334,
      "grad_norm": 0.06951774656772614,
      "learning_rate": 1.9169519053941788e-05,
      "loss": 0.0085,
      "step": 4150
    },
    {
      "epoch": 8.083724287260917,
      "grad_norm": 0.032366443425416946,
      "learning_rate": 1.742486587249873e-05,
      "loss": 0.0051,
      "step": 4200
    },
    {
      "epoch": 8.1799591002045,
      "grad_norm": 0.021378064528107643,
      "learning_rate": 1.575584740592685e-05,
      "loss": 0.0052,
      "step": 4250
    },
    {
      "epoch": 8.27619391314808,
      "grad_norm": 0.01682358793914318,
      "learning_rate": 1.4163992392110359e-05,
      "loss": 0.0066,
      "step": 4300
    },
    {
      "epoch": 8.372428726091664,
      "grad_norm": 0.012798837386071682,
      "learning_rate": 1.2650758891049463e-05,
      "loss": 0.007,
      "step": 4350
    },
    {
      "epoch": 8.468663539035246,
      "grad_norm": 0.07684537023305893,
      "learning_rate": 1.1217532949350073e-05,
      "loss": 0.0078,
      "step": 4400
    },
    {
      "epoch": 8.564898351978828,
      "grad_norm": 0.031066536903381348,
      "learning_rate": 9.865627330673888e-06,
      "loss": 0.0073,
      "step": 4450
    },
    {
      "epoch": 8.661133164922411,
      "grad_norm": 0.009547327645123005,
      "learning_rate": 8.596280313312355e-06,
      "loss": 0.0082,
      "step": 4500
    },
    {
      "epoch": 8.757367977865993,
      "grad_norm": 0.07030373066663742,
      "learning_rate": 7.410654555985286e-06,
      "loss": 0.0075,
      "step": 4550
    },
    {
      "epoch": 8.853602790809575,
      "grad_norm": 0.006205682177096605,
      "learning_rate": 6.309836032903227e-06,
      "loss": 0.0064,
      "step": 4600
    },
    {
      "epoch": 8.949837603753158,
      "grad_norm": 0.03847533464431763,
      "learning_rate": 5.294833039069269e-06,
      "loss": 0.0071,
      "step": 4650
    },
    {
      "epoch": 9.04607241669674,
      "grad_norm": 0.0034064340870827436,
      "learning_rate": 4.366575266730888e-06,
      "loss": 0.0064,
      "step": 4700
    },
    {
      "epoch": 9.142307229640322,
      "grad_norm": 0.03661860153079033,
      "learning_rate": 3.5259129538281033e-06,
      "loss": 0.0074,
      "step": 4750
    },
    {
      "epoch": 9.238542042583905,
      "grad_norm": 0.02976410463452339,
      "learning_rate": 2.7736161052178356e-06,
      "loss": 0.0087,
      "step": 4800
    },
    {
      "epoch": 9.334776855527487,
      "grad_norm": 0.036893121898174286,
      "learning_rate": 2.110373787387754e-06,
      "loss": 0.0062,
      "step": 4850
    },
    {
      "epoch": 9.431011668471069,
      "grad_norm": 0.020024267956614494,
      "learning_rate": 1.5367934973056996e-06,
      "loss": 0.0066,
      "step": 4900
    },
    {
      "epoch": 9.527246481414652,
      "grad_norm": 0.014018485322594643,
      "learning_rate": 1.053400605982613e-06,
      "loss": 0.0077,
      "step": 4950
    },
    {
      "epoch": 9.623481294358234,
      "grad_norm": 0.0066285585053265095,
      "learning_rate": 6.60637877258874e-07,
      "loss": 0.0059,
      "step": 5000
    },
    {
      "epoch": 9.719716107301817,
      "grad_norm": 0.0475638173520565,
      "learning_rate": 3.588650622546319e-07,
      "loss": 0.005,
      "step": 5050
    },
    {
      "epoch": 9.815950920245399,
      "grad_norm": 0.03530994430184364,
      "learning_rate": 1.4835856985568887e-07,
      "loss": 0.0053,
      "step": 5100
    },
    {
      "epoch": 9.91218573318898,
      "grad_norm": 0.0036350225564092398,
      "learning_rate": 2.9311213536686867e-08,
      "loss": 0.0056,
      "step": 5150
    },
    {
      "epoch": 9.989173583543847,
      "step": 5190,
      "total_flos": 5.72615186461738e+18,
      "train_loss": 0.03984273370922416,
      "train_runtime": 119824.7268,
      "train_samples_per_second": 0.694,
      "train_steps_per_second": 0.043
    }
  ],
  "logging_steps": 50,
  "max_steps": 5190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.72615186461738e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
